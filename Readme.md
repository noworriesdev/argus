# Using this repo

Everything is currently highly manual. For now I will document only the manual workflow parts of this repository. 

# Files and folders

## local_data

`local_data` is ... where the local data lives. It is in `.gitignore`. You need to make these folders manually. `local_data` should be at the root of your repository.

### csvs

The scripts as written dump the CSVs for `neo4j admin import` in this folder. 

### discord_json_dump

This is where you put the Discord JSON dump generated by `fetch_discord_messages`. 

### training_data

This is where the scripts as written dump the data for fine-tuning GPT3.5.

## scripts

The only relevant folders right now are `scripts/local` and `scripts/data_viz`. The data viz scripts are self-explanatory from the file names I think. 

### scripts/local

- `fetch_discord_messages`: Fetch Discord messages and dump them to `local_data/discord_json_dump/discord_messages.json`. 
- `generate_csv_for_import`: Take a JSON dump of a Discord and generate the CSVs for bulk import. You will need to execute the bulk import yourself following the instructions outlined [here](https://chat.openai.com/share/8a293441-2f79-42a1-9f34-af252374787a). Note that the actual command is `database import` and you only need this in the flags: `--nodes=file.csv`, `--relationships=file.csv`.
- `generate_training_data`: Given a Neo4j instance with the Discord loaded into it, create training data. Ask me for help if you start looking at this, I'm not going to document it right now. 
- `evaluate_fine_tuning_data`: This will give you some high-level stats and validations of your training data. 
- `create_fine_tuning_job`: Create the fine-tuning job. See instructions [here](https://platform.openai.com/docs/guides/fine-tuning).

# .env

You need to fill out an .env file for this to work. I made a sample with everything you need in `.env_template`. 